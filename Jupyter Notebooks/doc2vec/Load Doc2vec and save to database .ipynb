{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook result\n",
    "\n",
    "### Upload 10 similar research papers to the mysql database in table similar_papers\n",
    "\n",
    "Steps: \n",
    "\n",
    "1. load data arxiv_id for each catefory from database \n",
    "\n",
    "2. load saved model into memory \n",
    "\n",
    "3. save data to the memory in csv files for each category\n",
    "\n",
    "3. upload csv to the database \n",
    "\n",
    "4. close database connection \n",
    "\n",
    "\n",
    "\n",
    "### Remarks\n",
    "\n",
    "1. takes 20 minutes on MacBook air 2017\n",
    "\n",
    "2. not handle the edge cases for the duplicate entries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-03-07 14:05:02,417 : INFO : 'pattern' package not found; tag filters are not available for English\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from gensim.models import doc2vec\n",
    "from  gensim import matutils\n",
    "from collections import namedtuple\n",
    "from gensim.models import doc2vec\n",
    "import random\n",
    "from pandas.io import sql as sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pymysql.cursors\n",
    "\n",
    "connection = pymysql.connect(host='localhost',\n",
    "                             user='root',\n",
    "                             password='password123',\n",
    "                             db='arxivOverload',\n",
    "                             charset='utf8mb4',\n",
    "                             cursorclass=pymysql.cursors.DictCursor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# all queries \n",
    "\n",
    "astro_ph = \"select id, arxiv_id, title, abstract, primary_category from arxivOverload.METADATA where primary_category like 'astro-ph.%';\"\n",
    "cond_mat = \"select id, arxiv_id, title, abstract, primary_category from arxivOverload.METADATA where primary_category like 'cond-mat.%';\"\n",
    "esss = \"select id, arxiv_id, title, abstract, primary_category from arxivOverload.METADATA where primary_category like 'eess.%';\"\n",
    "econ = \"select id, arxiv_id, title, abstract, primary_category from arxivOverload.METADATA where primary_category like 'econ.%';\"\n",
    "cs = \"select id, arxiv_id, title, abstract, primary_category from arxivOverload.METADATA where primary_category like 'cs.%';\"\n",
    "hep = \"select id, arxiv_id, title, abstract, primary_category from arxivOverload.METADATA where primary_category like 'hep-%';\"\n",
    "maths = \"select id, arxiv_id, title, abstract, primary_category from arxivOverload.METADATA where primary_category like 'math.%';\"\n",
    "\n",
    "physics = \"select id, arxiv_id, title, abstract, primary_category from arxivOverload.METADATA where primary_category like 'physics.%';\"\n",
    "nlin = \"select id, arxiv_id, title, abstract, primary_category from arxivOverload.METADATA where primary_category like 'nlin.%';\"\n",
    "nucl = \"select id, arxiv_id, title, abstract, primary_category from arxivOverload.METADATA where primary_category like 'nucl-%';\"\n",
    "q_bio = \"select id, arxiv_id, title, abstract, primary_category from arxivOverload.METADATA where primary_category like 'q-bio.%';\"\n",
    "stats = \"select id, arxiv_id, title, abstract, primary_category from arxivOverload.METADATA where primary_category like 'stat.%';\"\n",
    "q_fin = \"select id, arxiv_id, title, abstract, primary_category from arxivOverload.METADATA where primary_category like 'q-fin.%';\"\n",
    "quant_ph = \"select id, arxiv_id, title, abstract, primary_category from arxivOverload.METADATA where primary_category like 'quant-%';\"\n",
    "gr_qc = \"select id, arxiv_id, title, abstract, primary_category from arxivOverload.METADATA where primary_category like 'gr-%';\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Similarity formula\n",
    "import math\n",
    "\n",
    "def Cosine(vec1, vec2) :\n",
    "    result = InnerProduct(vec1,vec2) / (VectorSize(vec1) * VectorSize(vec2))\n",
    "    return result\n",
    "\n",
    "def VectorSize(vec) :\n",
    "    return math.sqrt(sum(math.pow(v,2) for v in vec))\n",
    "\n",
    "def InnerProduct(vec1, vec2) :\n",
    "    return sum(v1*v2 for v1,v2 in zip(vec1,vec2))\n",
    "\n",
    "def Euclidean(vec1, vec2) :\n",
    "    return math.sqrt(sum(math.pow((v1-v2),2) for v1,v2 in zip(vec1, vec2)))\n",
    "\n",
    "def Theta(vec1, vec2) :\n",
    "    return math.acos(Cosine(vec1,vec2)) + 10\n",
    "\n",
    "def Triangle(vec1, vec2) :\n",
    "    theta = math.radians(Theta(vec1,vec2))\n",
    "    return (VectorSize(vec1) * VectorSize(vec2) * math.sin(theta)) / 2\n",
    "\n",
    "def Magnitude_Difference(vec1, vec2) :\n",
    "    return abs(VectorSize(vec1) - VectorSize(vec2))\n",
    "\n",
    "def Sector(vec1, vec2) :\n",
    "    ED = Euclidean(vec1, vec2)\n",
    "    MD = Magnitude_Difference(vec1, vec2)\n",
    "    theta = Theta(vec1, vec2)\n",
    "    return math.pi * math.pow((ED+MD),2) * theta/360\n",
    "\n",
    "def TS_SS(vec1, vec2) :\n",
    "    return Triangle(vec1, vec2) * Sector(vec1, vec2)\n",
    "\n",
    "def similarity(d1, d2):\n",
    "        \"\"\"\n",
    "        Compute cosine similarity between two docvecs in the trained set, specified by int index or\n",
    "        string tag. (TODO: Accept vectors of out-of-training-set docs, as if from inference.)\n",
    "        \"\"\"\n",
    "#         Triangle(vec1, vec2) * Sector(vec1, vec2)\n",
    "        return (Triangle(matutils.unitvec(d1), matutils.unitvec(d2)) * Sector(matutils.unitvec(d1), matutils.unitvec(d2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "astro_ph_df = pd.read_sql(astro_ph, con= connection)\n",
    "cond_mat_df = pd.read_sql(cond_mat, con=connection)\n",
    "esss_df = pd.read_sql(esss, con = connection)\n",
    "econ_df = pd.read_sql(econ, con = connection)\n",
    "cs_df = pd.read_sql(cs, con = connection)\n",
    "hep_df = pd.read_sql(hep, con = connection)\n",
    "maths_df = pd.read_sql(maths, con = connection)\n",
    "physics_df = pd.read_sql(physics, con = connection)\n",
    "nlin_df = pd.read_sql(nlin, con = connection)\n",
    "nucl_df = pd.read_sql(nucl, con = connection)\n",
    "q_bio_df = pd.read_sql(q_bio, con = connection)\n",
    "stats_df = pd.read_sql(stats, con = connection)\n",
    "q_fin_df = pd.read_sql(q_fin, con = connection)\n",
    "quant_ph_df = pd.read_sql(quant_ph, con = connection)\n",
    "gr_qc_df = pd.read_sql(gr_qc, con = connection)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataframes =     [astro_ph_df, cond_mat_df, esss_df, econ_df, cs_df, hep_df, maths_df, physics_df, nlin_df, nucl_df, q_bio_df, stats_df, q_fin_df, quant_ph_df, gr_qc_df]\n",
    "category_names = ['astro_ph', 'cond_mat', 'esss', 'econ', 'cs', 'hep', 'maths', 'physics', 'nlin', 'nucl', 'q_bio', 'stats', 'q_fin', 'quant_ph', 'gr_qc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-03-07 14:27:25,739 : INFO : loading Doc2Vec object from astro_ph\n",
      "2018-03-07 14:27:26,036 : INFO : loading vocabulary recursively from astro_ph.vocabulary.* with mmap=None\n",
      "2018-03-07 14:27:26,038 : INFO : loading trainables recursively from astro_ph.trainables.* with mmap=None\n",
      "2018-03-07 14:27:26,039 : INFO : loading wv recursively from astro_ph.wv.* with mmap=None\n",
      "2018-03-07 14:27:26,042 : INFO : loading docvecs recursively from astro_ph.docvecs.* with mmap=None\n",
      "2018-03-07 14:27:26,044 : INFO : loading vectors_docs from astro_ph.docvecs.vectors_docs.npy with mmap=None\n",
      "2018-03-07 14:27:26,738 : INFO : loaded astro_ph\n",
      "2018-03-07 14:27:26,744 : INFO : loading Doc2Vec object from cond_mat\n",
      "2018-03-07 14:27:27,220 : INFO : loading vocabulary recursively from cond_mat.vocabulary.* with mmap=None\n",
      "2018-03-07 14:27:27,221 : INFO : loading trainables recursively from cond_mat.trainables.* with mmap=None\n",
      "2018-03-07 14:27:27,223 : INFO : loading wv recursively from cond_mat.wv.* with mmap=None\n",
      "2018-03-07 14:27:27,225 : INFO : loading docvecs recursively from cond_mat.docvecs.* with mmap=None\n",
      "2018-03-07 14:27:27,227 : INFO : loading vectors_docs from cond_mat.docvecs.vectors_docs.npy with mmap=None\n",
      "2018-03-07 14:27:27,997 : INFO : loaded cond_mat\n",
      "2018-03-07 14:27:28,001 : INFO : loading Doc2Vec object from esss\n",
      "2018-03-07 14:27:28,206 : INFO : loading vocabulary recursively from esss.vocabulary.* with mmap=None\n",
      "2018-03-07 14:27:28,207 : INFO : loading trainables recursively from esss.trainables.* with mmap=None\n",
      "2018-03-07 14:27:28,208 : INFO : loading wv recursively from esss.wv.* with mmap=None\n",
      "2018-03-07 14:27:28,211 : INFO : loading docvecs recursively from esss.docvecs.* with mmap=None\n",
      "2018-03-07 14:27:28,213 : INFO : loaded esss\n",
      "2018-03-07 14:27:28,215 : INFO : loading Doc2Vec object from econ\n",
      "2018-03-07 14:27:28,228 : INFO : loading vocabulary recursively from econ.vocabulary.* with mmap=None\n",
      "2018-03-07 14:27:28,230 : INFO : loading trainables recursively from econ.trainables.* with mmap=None\n",
      "2018-03-07 14:27:28,233 : INFO : loading wv recursively from econ.wv.* with mmap=None\n",
      "2018-03-07 14:27:28,236 : INFO : loading docvecs recursively from econ.docvecs.* with mmap=None\n",
      "2018-03-07 14:27:28,239 : INFO : loaded econ\n",
      "2018-03-07 14:27:28,242 : INFO : loading Doc2Vec object from cs\n",
      "2018-03-07 14:27:28,405 : INFO : loading vocabulary recursively from cs.vocabulary.* with mmap=None\n",
      "2018-03-07 14:27:28,407 : INFO : loading trainables recursively from cs.trainables.* with mmap=None\n",
      "2018-03-07 14:27:28,409 : INFO : loading wv recursively from cs.wv.* with mmap=None\n",
      "2018-03-07 14:27:28,414 : INFO : loading docvecs recursively from cs.docvecs.* with mmap=None\n",
      "2018-03-07 14:27:28,417 : INFO : loading vectors_docs from cs.docvecs.vectors_docs.npy with mmap=None\n",
      "2018-03-07 14:27:29,409 : INFO : loaded cs\n",
      "2018-03-07 14:27:29,410 : INFO : loading Doc2Vec object from hep\n",
      "2018-03-07 14:27:29,805 : INFO : loading vocabulary recursively from hep.vocabulary.* with mmap=None\n",
      "2018-03-07 14:27:29,808 : INFO : loading trainables recursively from hep.trainables.* with mmap=None\n",
      "2018-03-07 14:27:29,812 : INFO : loading wv recursively from hep.wv.* with mmap=None\n",
      "2018-03-07 14:27:29,817 : INFO : loading docvecs recursively from hep.docvecs.* with mmap=None\n",
      "2018-03-07 14:27:29,820 : INFO : loaded hep\n",
      "2018-03-07 14:27:29,824 : INFO : loading Doc2Vec object from maths\n",
      "2018-03-07 14:27:30,383 : INFO : loading vocabulary recursively from maths.vocabulary.* with mmap=None\n",
      "2018-03-07 14:27:30,385 : INFO : loading trainables recursively from maths.trainables.* with mmap=None\n",
      "2018-03-07 14:27:30,388 : INFO : loading wv recursively from maths.wv.* with mmap=None\n",
      "2018-03-07 14:27:30,391 : INFO : loading docvecs recursively from maths.docvecs.* with mmap=None\n",
      "2018-03-07 14:27:30,401 : INFO : loaded maths\n",
      "2018-03-07 14:27:30,403 : INFO : loading Doc2Vec object from physics\n",
      "2018-03-07 14:27:31,145 : INFO : loading vocabulary recursively from physics.vocabulary.* with mmap=None\n",
      "2018-03-07 14:27:31,147 : INFO : loading trainables recursively from physics.trainables.* with mmap=None\n",
      "2018-03-07 14:27:31,148 : INFO : loading wv recursively from physics.wv.* with mmap=None\n",
      "2018-03-07 14:27:31,151 : INFO : loading docvecs recursively from physics.docvecs.* with mmap=None\n",
      "2018-03-07 14:27:31,153 : INFO : loaded physics\n",
      "2018-03-07 14:27:31,156 : INFO : loading Doc2Vec object from nlin\n",
      "2018-03-07 14:27:31,595 : INFO : loading vocabulary recursively from nlin.vocabulary.* with mmap=None\n",
      "2018-03-07 14:27:31,597 : INFO : loading trainables recursively from nlin.trainables.* with mmap=None\n",
      "2018-03-07 14:27:31,598 : INFO : loading wv recursively from nlin.wv.* with mmap=None\n",
      "2018-03-07 14:27:31,601 : INFO : loading docvecs recursively from nlin.docvecs.* with mmap=None\n",
      "2018-03-07 14:27:31,603 : INFO : loaded nlin\n",
      "2018-03-07 14:27:31,606 : INFO : loading Doc2Vec object from nucl\n",
      "2018-03-07 14:27:31,862 : INFO : loading vocabulary recursively from nucl.vocabulary.* with mmap=None\n",
      "2018-03-07 14:27:31,864 : INFO : loading trainables recursively from nucl.trainables.* with mmap=None\n",
      "2018-03-07 14:27:31,866 : INFO : loading wv recursively from nucl.wv.* with mmap=None\n",
      "2018-03-07 14:27:31,868 : INFO : loading docvecs recursively from nucl.docvecs.* with mmap=None\n",
      "2018-03-07 14:27:31,870 : INFO : loaded nucl\n",
      "2018-03-07 14:27:31,878 : INFO : loading Doc2Vec object from q_bio\n",
      "2018-03-07 14:27:32,336 : INFO : loading vocabulary recursively from q_bio.vocabulary.* with mmap=None\n",
      "2018-03-07 14:27:32,337 : INFO : loading trainables recursively from q_bio.trainables.* with mmap=None\n",
      "2018-03-07 14:27:32,339 : INFO : loading wv recursively from q_bio.wv.* with mmap=None\n",
      "2018-03-07 14:27:32,341 : INFO : loading docvecs recursively from q_bio.docvecs.* with mmap=None\n",
      "2018-03-07 14:27:32,343 : INFO : loaded q_bio\n",
      "2018-03-07 14:27:32,351 : INFO : loading Doc2Vec object from stats\n",
      "2018-03-07 14:27:32,523 : INFO : loading vocabulary recursively from stats.vocabulary.* with mmap=None\n",
      "2018-03-07 14:27:32,525 : INFO : loading trainables recursively from stats.trainables.* with mmap=None\n",
      "2018-03-07 14:27:32,527 : INFO : loading wv recursively from stats.wv.* with mmap=None\n",
      "2018-03-07 14:27:32,530 : INFO : loading docvecs recursively from stats.docvecs.* with mmap=None\n",
      "2018-03-07 14:27:32,532 : INFO : loaded stats\n",
      "2018-03-07 14:27:32,538 : INFO : loading Doc2Vec object from q_fin\n",
      "2018-03-07 14:27:32,720 : INFO : loading vocabulary recursively from q_fin.vocabulary.* with mmap=None\n",
      "2018-03-07 14:27:32,722 : INFO : loading trainables recursively from q_fin.trainables.* with mmap=None\n",
      "2018-03-07 14:27:32,725 : INFO : loading wv recursively from q_fin.wv.* with mmap=None\n",
      "2018-03-07 14:27:32,728 : INFO : loading docvecs recursively from q_fin.docvecs.* with mmap=None\n",
      "2018-03-07 14:27:32,730 : INFO : loaded q_fin\n",
      "2018-03-07 14:27:32,740 : INFO : loading Doc2Vec object from quant_ph\n",
      "2018-03-07 14:27:33,500 : INFO : loading vocabulary recursively from quant_ph.vocabulary.* with mmap=None\n",
      "2018-03-07 14:27:33,502 : INFO : loading trainables recursively from quant_ph.trainables.* with mmap=None\n",
      "2018-03-07 14:27:33,504 : INFO : loading wv recursively from quant_ph.wv.* with mmap=None\n",
      "2018-03-07 14:27:33,507 : INFO : loading docvecs recursively from quant_ph.docvecs.* with mmap=None\n",
      "2018-03-07 14:27:33,509 : INFO : loaded quant_ph\n",
      "2018-03-07 14:27:33,527 : INFO : loading Doc2Vec object from gr_qc\n",
      "2018-03-07 14:27:33,665 : INFO : loading vocabulary recursively from gr_qc.vocabulary.* with mmap=None\n",
      "2018-03-07 14:27:33,666 : INFO : loading trainables recursively from gr_qc.trainables.* with mmap=None\n",
      "2018-03-07 14:27:33,668 : INFO : loading wv recursively from gr_qc.wv.* with mmap=None\n",
      "2018-03-07 14:27:33,670 : INFO : loading docvecs recursively from gr_qc.docvecs.* with mmap=None\n",
      "2018-03-07 14:27:33,672 : INFO : loaded gr_qc\n"
     ]
    }
   ],
   "source": [
    "astro_ph_model = Doc2Vec.load('astro_ph')\n",
    "cond_mat_model = Doc2Vec.load('cond_mat')\n",
    "esss_model = Doc2Vec.load('esss')\n",
    "econ_model = Doc2Vec.load('econ') \n",
    "cs_model = Doc2Vec.load('cs')\n",
    "hep_model = Doc2Vec.load('hep')\n",
    "maths_model = Doc2Vec.load('maths')\n",
    "physics_model = Doc2Vec.load('physics')\n",
    "nlin_model = Doc2Vec.load('nlin')\n",
    "nucl_model = Doc2Vec.load('nucl')\n",
    "q_bio_model = Doc2Vec.load('q_bio')\n",
    "stats_model = Doc2Vec.load('stats')\n",
    "q_fin_model = Doc2Vec.load('q_fin')\n",
    "quant_ph_model = Doc2Vec.load('quant_ph')\n",
    "gr_qc_model = Doc2Vec.load('gr_qc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models = [astro_ph_model, cond_mat_model, esss_model, econ_model, cs_model, hep_model, maths_model, physics_model, nlin_model, nucl_model, q_bio_model, stats_model, q_fin_model, quant_ph_model, gr_qc_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "def save_to_csv(connection, dataframes, models, category_names):\n",
    "        for dataframe ,model , category in zip(dataframes, models , category_names):\n",
    "            main_list=[]\n",
    "            for i in dataframe[\"arxiv_id\"]:\n",
    "                data = {}\n",
    "                arxiv_list = []\n",
    "                similarity = model.docvecs.most_similar(i)\n",
    "                for j , k in similarity:\n",
    "                    arxiv_list.append(i)\n",
    "                data[\"arxiv_id\"] = i\n",
    "                data[\"similar_papers\"] = json.dumps(arxiv_list)\n",
    "                main_list.append(data)        \n",
    "            df = pd.DataFrame(main_list)\n",
    "#             print(df.head())\n",
    "            df.to_csv(\"similarity data/\"+category+\".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-03-07 14:57:21,038 : INFO : precomputing L2-norms of doc weight vectors\n",
      "2018-03-07 14:57:23,875 : INFO : precomputing L2-norms of doc weight vectors\n",
      "2018-03-07 14:57:32,380 : INFO : precomputing L2-norms of doc weight vectors\n",
      "2018-03-07 14:57:34,189 : INFO : precomputing L2-norms of doc weight vectors\n",
      "2018-03-07 14:57:36,016 : INFO : precomputing L2-norms of doc weight vectors\n",
      "2018-03-07 14:58:02,188 : INFO : precomputing L2-norms of doc weight vectors\n"
     ]
    }
   ],
   "source": [
    "save_to_csv(connection, dataframes, models, category_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pymysql\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "# creating engine \n",
    "engine = create_engine('mysql+pymysql://root:password123@localhost:3306/arxivOverload', echo=False)\n",
    "\n",
    "def upload_recommended_items(category_names):\n",
    "    for category_name in category_names:\n",
    "        data = pd.read_csv(\"similarity data/\"+category_name+\".csv\")\n",
    "        table_name = \"similar_papers\"\n",
    "        data.to_sql(name=table_name, con=engine, if_exists = 'append', index=False)\n",
    "        print(\"dataframe to sql\")\n",
    "        print(\"Entries successfully uploaded to mysql server\", category_name)\n",
    "    engine.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/prakritidevverma/anaconda3/lib/python3.6/site-packages/pymysql/cursors.py:165: Warning: (1287, \"'@@tx_isolation' is deprecated and will be removed in a future release. Please use '@@transaction_isolation' instead\")\n",
      "  result = self._query(query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataframe to sql\n",
      "Entries successfully uploaded to mysql server astro_ph\n",
      "dataframe to sql\n",
      "Entries successfully uploaded to mysql server cond_mat\n",
      "dataframe to sql\n",
      "Entries successfully uploaded to mysql server esss\n",
      "dataframe to sql\n",
      "Entries successfully uploaded to mysql server econ\n",
      "dataframe to sql\n",
      "Entries successfully uploaded to mysql server cs\n",
      "dataframe to sql\n",
      "Entries successfully uploaded to mysql server hep\n",
      "dataframe to sql\n",
      "Entries successfully uploaded to mysql server maths\n",
      "dataframe to sql\n",
      "Entries successfully uploaded to mysql server physics\n",
      "dataframe to sql\n",
      "Entries successfully uploaded to mysql server nlin\n",
      "dataframe to sql\n",
      "Entries successfully uploaded to mysql server nucl\n",
      "dataframe to sql\n",
      "Entries successfully uploaded to mysql server q_bio\n",
      "dataframe to sql\n",
      "Entries successfully uploaded to mysql server stats\n",
      "dataframe to sql\n",
      "Entries successfully uploaded to mysql server q_fin\n",
      "dataframe to sql\n",
      "Entries successfully uploaded to mysql server quant_ph\n",
      "dataframe to sql\n",
      "Entries successfully uploaded to mysql server gr_qc\n"
     ]
    }
   ],
   "source": [
    "upload_recommended_items(category_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
